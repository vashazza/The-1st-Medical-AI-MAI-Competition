{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lci0_xCqK81",
        "outputId": "ca21f115-d884-4d91-f5e1-d99e44e864ab"
      },
      "id": "9lci0_xCqK81",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
      "metadata": {
        "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
        "outputId": "75f319d3-29e3-46a7-bec7-896c159164bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.17 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import torchvision.models as models\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d13862e3-bb27-47af-9b58-a9fbf804df71",
      "metadata": {
        "id": "d13862e3-bb27-47af-9b58-a9fbf804df71"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc7df3f2-62d0-4499-a46e-47d01699def0",
      "metadata": {
        "id": "fc7df3f2-62d0-4499-a46e-47d01699def0"
      },
      "source": [
        "## Hyperparameter Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
      "metadata": {
        "id": "c3367399-9798-4e38-967b-fd2320b9a2b2"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    'IMG_SIZE':224,\n",
        "    'EPOCHS':5,\n",
        "    'LEARNING_RATE':3e-4,\n",
        "    'BATCH_SIZE':32,\n",
        "    'SEED':41\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd",
      "metadata": {
        "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd"
      },
      "source": [
        "## Fixed RandomSeed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731",
      "metadata": {
        "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05a4172e-5791-446f-9616-35c09d8bf25a",
      "metadata": {
        "id": "05a4172e-5791-446f-9616-35c09d8bf25a"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_DIR = '/content/drive/MyDrive/2024_MAI_DACON/Open/'\n",
        "%cd /content/drive/MyDrive/2024_MAI_DACON/Open"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oDDpP8xqYOU",
        "outputId": "8c8e4b14-6ed6-451d-f734-afb87a38fbb9"
      },
      "id": "5oDDpP8xqYOU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/2024_MAI_DACON/Open\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d",
      "metadata": {
        "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(os.path.join(ROOT_DIR, 'train.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db41c93-3515-4fcd-936b-0a01f5388b3f",
      "metadata": {
        "id": "4db41c93-3515-4fcd-936b-0a01f5388b3f"
      },
      "outputs": [],
      "source": [
        "train_len = int(len(df) * 0.8)\n",
        "train_df = df.iloc[:train_len]\n",
        "val_df = df.iloc[train_len:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c8c5916-8065-4b5c-aa37-f3fb2b9fa422",
      "metadata": {
        "id": "6c8c5916-8065-4b5c-aa37-f3fb2b9fa422"
      },
      "outputs": [],
      "source": [
        "train_label_vec = train_df.iloc[:,2:].values.astype(np.float32)\n",
        "val_label_vec = val_df.iloc[:,2:].values.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "529a17e8-7d58-48d4-b474-5b72e8665321",
      "metadata": {
        "id": "529a17e8-7d58-48d4-b474-5b72e8665321"
      },
      "outputs": [],
      "source": [
        "CFG['label_size'] = train_label_vec.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e",
      "metadata": {
        "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e"
      },
      "source": [
        "## CustomDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16fd60a5-24e2-4539-bfd0-1c374a641699",
      "metadata": {
        "id": "16fd60a5-24e2-4539-bfd0-1c374a641699"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_path_list, label_list, transforms=None):\n",
        "        self.img_path_list = img_path_list\n",
        "        self.label_list = label_list\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.img_path_list[index]\n",
        "\n",
        "        image = cv2.imread(img_path)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image=image)['image']\n",
        "\n",
        "        if self.label_list is not None:\n",
        "            label = self.label_list[index]\n",
        "            return image, label\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "340b4a8b-5d6c-413f-b8b6-066e91a660e5",
      "metadata": {
        "id": "340b4a8b-5d6c-413f-b8b6-066e91a660e5"
      },
      "outputs": [],
      "source": [
        "train_transform = A.Compose([\n",
        "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
        "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "                            ToTensorV2()\n",
        "                            ])\n",
        "\n",
        "test_transform = A.Compose([\n",
        "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
        "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "                            ToTensorV2()\n",
        "                            ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d880481-1965-499d-9caa-fdfa8526f789",
      "metadata": {
        "id": "9d880481-1965-499d-9caa-fdfa8526f789"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(train_df['path'].values, train_label_vec, train_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "val_dataset = CustomDataset(val_df['path'].values, val_label_vec, test_transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39962463-032f-490a-a76d-c03991795f38",
      "metadata": {
        "id": "39962463-032f-490a-a76d-c03991795f38"
      },
      "source": [
        "## Model Define"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3664c4d0-f1f2-4971-9090-4d6ee66309ae",
      "metadata": {
        "id": "3664c4d0-f1f2-4971-9090-4d6ee66309ae"
      },
      "outputs": [],
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, gene_size=CFG['label_size']):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.backbone = models.resnet50(pretrained=True)\n",
        "        self.regressor = nn.Linear(1000, gene_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.regressor(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "122af0aa-a1fd-4595-9488-35761e3cb596",
      "metadata": {
        "id": "122af0aa-a1fd-4595-9488-35761e3cb596"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749",
      "metadata": {
        "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
        "    model.to(device)\n",
        "    criterion = nn.MSELoss().to(device)\n",
        "\n",
        "    best_loss = 99999999\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(1, CFG['EPOCHS']+1):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "        for imgs, labels in tqdm(iter(train_loader)):\n",
        "            imgs = imgs.float().to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(imgs)\n",
        "            loss = criterion(output, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        _val_loss = validation(model, criterion, val_loader, device)\n",
        "        _train_loss = np.mean(train_loss)\n",
        "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}]')\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(_val_loss)\n",
        "\n",
        "        if best_loss > _val_loss:\n",
        "            best_loss = _val_loss\n",
        "            best_model = model\n",
        "\n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96b1c524-89fb-4ce8-a49f-067fd489f84a",
      "metadata": {
        "id": "96b1c524-89fb-4ce8-a49f-067fd489f84a"
      },
      "outputs": [],
      "source": [
        "def validation(model, criterion, val_loader, device):\n",
        "    model.eval()\n",
        "    val_loss = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm(iter(val_loader)):\n",
        "            imgs = imgs.float().to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            pred = model(imgs)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "        _val_loss = np.mean(val_loss)\n",
        "\n",
        "    return _val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24",
      "metadata": {
        "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24"
      },
      "source": [
        "## Run!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86142d9a-68b7-4d04-8423-49d28025411d",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86142d9a-68b7-4d04-8423-49d28025411d",
        "outputId": "24d88486-383c-469d-9d64-979b86b70e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [1:12:45<00:00, 24.94s/it]\n",
            "100%|██████████| 44/44 [17:19<00:00, 23.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], Train Loss : [0.06512] Val Loss : [0.04849]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:39<00:00,  1.75it/s]\n",
            "100%|██████████| 44/44 [00:14<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2], Train Loss : [0.04804] Val Loss : [0.04762]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:39<00:00,  1.76it/s]\n",
            "100%|██████████| 44/44 [00:14<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3], Train Loss : [0.04715] Val Loss : [0.04709]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:39<00:00,  1.76it/s]\n",
            "100%|██████████| 44/44 [00:14<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4], Train Loss : [0.04670] Val Loss : [0.04684]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [01:40<00:00,  1.74it/s]\n",
            "100%|██████████| 44/44 [00:14<00:00,  3.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5], Train Loss : [0.04626] Val Loss : [0.04657]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = BaseModel()\n",
        "model.eval()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
        "\n",
        "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e275a486-9c59-4b4e-80f6-5000e017b921",
      "metadata": {
        "id": "e275a486-9c59-4b4e-80f6-5000e017b921"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ed16d0e-61ee-4737-b90a-3842860cc40a",
      "metadata": {
        "id": "0ed16d0e-61ee-4737-b90a-3842860cc40a"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('./test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbbf9ae5-9d8c-4800-a809-63094a1e9a24",
      "metadata": {
        "id": "dbbf9ae5-9d8c-4800-a809-63094a1e9a24"
      },
      "outputs": [],
      "source": [
        "test_dataset = CustomDataset(test['path'].values, None, test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "378fd3a9-76d8-4c9a-81a1-c6a48492684c",
      "metadata": {
        "id": "378fd3a9-76d8-4c9a-81a1-c6a48492684c"
      },
      "outputs": [],
      "source": [
        "def inference(model, test_loader, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs in tqdm(test_loader):\n",
        "            imgs = imgs.to(device).float()\n",
        "            pred = model(imgs)\n",
        "\n",
        "            preds.append(pred.detach().cpu())\n",
        "\n",
        "    preds = torch.cat(preds).numpy()\n",
        "\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2866935c-407d-4919-a58b-1f8feaa66a2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2866935c-407d-4919-a58b-1f8feaa66a2a",
        "outputId": "20f55b01-88c8-43f9-f872-4334c14ce353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 72/72 [32:23<00:00, 26.99s/it]\n"
          ]
        }
      ],
      "source": [
        "preds = inference(infer_model, test_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35be0d25-6a06-43bb-bca0-94eda2409a26",
      "metadata": {
        "id": "35be0d25-6a06-43bb-bca0-94eda2409a26"
      },
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc864be2-c306-4ad0-aa97-1d5ab5ea9811",
      "metadata": {
        "id": "fc864be2-c306-4ad0-aa97-1d5ab5ea9811"
      },
      "outputs": [],
      "source": [
        "submit = pd.read_csv('./sample_submission.csv')\n",
        "submit.iloc[:, 1:] = np.array(preds).astype(np.float32)\n",
        "submit.to_csv('./baseline_submit.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gimin_py38",
      "language": "python",
      "name": "gimin_py38"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}